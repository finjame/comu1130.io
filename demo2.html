<!DOCTYPE html>
<html lang='en'>
<head>
  <title>Deepfakes?</title>
  <meta charset='UTF-8'/>
  <link rel='stylesheet' href='styles.css'/>
</head>
<body>
    <div class="overlay"></div>
     <video autoplay muted loop id="myVideo">
    <source src="https://video.wixstatic.com/video/11062b_35e9c1a919df41df8b95c20340739349/1080p/mp4/file.mp4" type="video/mp4" id="bgvid">
</video>
  	<nav>
      <div class='header'>
        <div class='logo'><h1>DEEPFAKES: AN INTERNET WE CAN TRUST?</h1>
        <p id="title" ><em> A Website created by James Finnimore</em></p></div>
        <ul id="list">
         <li class="nav-item active">
          <a class= "nav-link scroll" href="#page1"><em>Introduction</em></a>
          </li>
  		 	  <li class="nav-item">
            <a class="nav-link scroll" href="#page2"><em>Overview</em></a></li>
  		 	  <li class="nav-item">
            <a class="nav-link scroll" href="#page3"><em>Analysis</em></a></li>
  		 	  <li class="nav-item">
            <a class="nav-link scroll" href="#page4"><em>Conclusion</em></a></li>
  		 </ul>
     </div>
  	</nav>

    <div id="leadPage" class="smooth"></a>
        <p> halou baybay!!</p>
        <img src='images/first.jpg' width=100% height=710px z-index=-10/>
        <br>
        <br>

  </div>

  <div id="page1" class="smooth"></a>
    <div class="page-content">
      <h1> Introduction:</h1>
      <br>
      <h2> The Best Place to Start</h2>
      <br>
      <p class= "justify">In Philip K Dick’s 1957 book, The Cosmic Puppets, a man returns to his hometown after years of living elsewhere, only to find that not only has the landscape of the place changed, but it’s entire history too. (Dick, 1957) Upon arrival, he discovers that he hasn’t been written out of the town’s history completely: he finds a mention of him in the obituary section of the local paper, describing his death at age nine from scarlet fever. Instead of leaving the town in his youth, he has, according to the alternative reality in which the town sits, been dead since that time. Disgruntled, the man works with another similarly thinking town member, and together, slowly strip away the veil of faux reality which has been laid over their world, uncovering the real town hidden beneath. (Dick, 1957)</p>
      <br>
      <br>
      <p class= "justify">The narrative of a protagonist, suspect of the constructed nature of the world around them is a common one, and is often times classified as “paranoid science fiction” – itself defined as a genre where “protagonists are plagued with vague intuitions of the stage-managed falsity of their perceptual experience or delusory nature of their very identities.” (Westphal, 2005) Indeed, the idea that one’s environment is artificial, or even simulated, has been around for centuries, spanning from Rene Descartes’ 1641 proposition that humans are controlled by an evil demon who can “make [him] see, hear and feel an external reality” right up to the more widely known ‘Matrix’ trilogy. (Descartes, 1641) </p>
      <br>
      <br>
      <p class="justify">As the name infers, the world of “paranoid science fiction” is only that – fiction. After all, in each the examples mentioned above, the simulated nature of reality has been the result of a supernatural, or somewhat alien force imagined by the author.</p>
      <br>
      <br>
      <p class="justify">But increasingly, the power to influence and distort reality may not solely belong to the realms of fictitious “alien overlords” or “demonic presences”, but rather, to anyone with widely available, free-to-download computer editing software. Indeed, with new technology, individuals even with modest skill levels may now have the ability to create convincingly realistic representations of events that have never occurred, and associate people with actions they never performed. (Blitz, 2018)</p>
      <br>
      <br>
      <p class="justify">Commonly referred to as ‘Deep Fake’ technology, these practices of image, sound and video manipulation present an (often sinister) issue for modern society, particularly with the increasing frequency of such things as ‘fake news’. (Chesney & Citron, 2018)</p>
      <br>
      <br>
      <p class= "justify">The following pages will unpack the issue of ‘Deep Fakes’ and its perils, outline the zeitgeist of academic thought on the matter, and finally, present methods with which to combat it. </p>

    </div>


  	<div id="page2" class="smooth"></a>
      <div class="page-content">
        <video autoplay muted loop id="Donvid" width=90% height=auto position=center>
          <source src="https://abcmedia.akamaized.net/news/video/201809/Obamatrumpls.mp4" type="video/mp4" id="firstvid">
        </video>
        <p><em>Video source: (Australian Broadcoasting Commission, 2018)</em></p>
        <br>
        <br>
        <br>
        <br>
        <h1> Overview:</h1>
        <br>
        <h2> What are the dangers associated with the rise of deep fake technology?</h2>
        <br>
        <br>
		<p class= "justify">“Harmful lies”, as Robert Chesney – top Lawyer and Professor at the University of Texas – asserts, “are nothing new.”</p>
        <br>
        <br>
        <p class= "justify">  Yet, whilst this may be the case, the rapid rate at which digital technologies are improving – and as such, becoming more realistic – may just increase the impact such lies have on online audiences.</p>
        <br>
        <br>
        <p class= "justify">In order to demonstrate this, Chesney and Citron (2018) offered readers a number of terrifying possibilities for ‘deep fakes’, hinting at the consequences of fake videos portraying such things as “public officials taking bribes, engaging in adultery” and even “falsely ‘announcing’ an impending missile strike, provoking panic and worse.” (Chesney & Citron, 2018)</p>
        <br>
        <br>
        <p class= "justify">The word itself, ‘Deepfakes’, originates from the username of an anonymous Reddit user (or “Redditor”, as they are commonly referred) who, over the course of 2017, released a number of hardcore pornographic videos featuring the faces of a numerous female actresses – namely, Scarlett Johansson, Maisie Williams, Taylor Swift and Gal Gadot – onto the site. (Cole, 2017)</p>
        <br>
        <br>
        <p class= "justify">During correspondence with Motherboard.com’s Samantha Cole, 'deepfakes' (the user) revealed that the software utilised in creating the content which now bears his namesake is easily accessible, based on multiple open-source libraries. What’s more, deepfakes claims that amassing the image collection of celebrity faces (the source content used by artificial intelligence to project faux faces) is a simple matter of Google image searches, YouTube videos, and stock photo websites. Indeed, as Cole asserts, such ease of practice, in combination with the hundreds of billions of selfies and other face-focussed images present online, leaves a reality whereby anyone, anywhere is at risk of fake videos being created of them. (Cole, 2017)</p>
        <br>
        <br>
        <p class= "justify"> Yet, whilst these factors will remain a significant threat for users of the internet as a whole, <a class="link2" href="https://www.abc.net.au/news/2018-09-27/fake-news-part-one/10308638"><em>this article</em></a> from the ABC floats the idea that the technology’s most dangerous element isn’t one downloaded from any software source website, but rather, exists within society as a whole.</p>
        <br>
        <br>
        <p class= "justify">Written by Tim Leslie, Nathan Hoad and Ben Spraggon, the article suggests that the real threat of ‘Deep Fakes’ lies within the lack of understanding and nous on the subject held by people online.</p>
        <br>
        <br>
        <p class= "justify">Using a survey conducted on the link featured within this webpage, the tendencies of internet users (primarily between the ages of 17-20) were recorded and analysed. The results revealed several alarming facts. </p>
        <br>
        <br>
        <p class= "justify">When asked if they knew what ‘Deep Fakes’ were, an overwhelming 85% of users claimed they didn’t. (See below)</p>
        <br>
        <br>
        <br>
        <img src='images/heard.jpg' width=50% height=auto />
        <br>
        <br>
        <br>
        <p class= "justify">Similarly, when asked to 'spot the fake' from synchronised video loops of Obama and Trump ( the latter of which is the fake), a significant percentage – around 30% - wrongly selected the ‘real’ individual, whilst more than 35% incorrectly guessed that both were ‘fakes’. The video comparison can be found at the top of this segment.</p>
        <br>
        <br>
        <br>
        <br>
        <img src='images/obtrump.jpg' width=50% height=auto />
        <br>
        <br>
        <br>
        <p class= "justify">These secondary findings are substantiated by the same ABC article’s own comparison test, which showed that when asked to determine between video of Vladimir Putin and Theresa May, only 30% users answered correctly, selecting May as the ‘fake’ from the pair. (Lesie, Hoad, & Spraggon, 2018)</p>
        <br>
        <br>
        <p class= "justify">As the authors of that ABC article suggest, findings such as these illuminate the deeper problem perfectly. </p>
        <br>
        <p class= "justify">That problem?</p>
        <br>
        <p class= "justify">That we, as frequent consumers of mass media, have developed our understanding of the world largely through the same footage used by creators of fake content, and because of this, are dangerously overconfident in our ability to judge reality. Indeed, one 2007 study, it was concluded that a large proportion of internet users are grossly overconfident in their ability to determine the credibility of information and that many “thought they knew more than they actually did.” (Wang, 2007)</p>


    <div id="page3" class="smooth"></a>
      <div class="page-content">
      <h1> Analysis:</h1>
      <br>
		<h2> So, how exactly do we combat ‘Deep fakes?’</h2>
    <br>
    <br>
    <p class= "justify">In fairness, this overconfidence is not entirely the fault of individual users, but rather the result of a collective ‘norm’. Indeed, as a society, we’ve become accustomed to the idea that ‘seeing is believing’; of turning on the television or scrolling through Facebook, and not questioning that upon which we rest our gaze. And, as the findings of the above survey demonstrate, this process often leaves us exposed to deceptively realistic-looking content.</p>
    <br>
    <br>
    <p class= "justify">This lack of understanding into the topic, particularly one so widely documented, is frightening – especially when considering the targeted demographic is one frequently referred to by academics as ‘The Net Generation’. (Combes, 2008)  After all, if this generation, dubbed to have the most “in-depth grasp and ‘intuitive knowledge’ of how to use technology”, can’t pick the real from the false, then what hope is there for older, less technologically-inclined internet users? (Combes, 2008)</p>
    <br>
    <br>
    <p class= "justify">Little, it would seem, if we choose to rely upon digital programmes to do the ‘picking’ for us.</p>
    <br>
    <br>
    <p class= "justify"> Indeed, as Cole explains, to rely upon computerised programmes is to submit ourselves to an eternal game of ‘cat and mouse’ between ‘deep fake’ developers and those developing systems which identify them. After all, as one solution emerges for detection – like the identification of discrepancies in the way ‘faked’ individuals blink by researchers at the University of Albany – a way around this method emerges to match it. (Cole, There Is No Tech Solution to Deepfakes, 2018) Thus, whilst technologies are being developed, it’s unlikely that (at least in the short-term) that these will present organisations with any kind of ‘silver bullet’ solution.</p>
    <br>
    <br>
    <p class= "justify"> That being said, however, there may still be hope yet. </p>
    <br>
    <br>
    <p class= "justify"> According to Paul Resnick, a social media expert at the University of Michigan, the prominence of ‘deep fakes’ may simply lead to the public heightening it’s scepticism of online video content, with users adjusting in a similar way that it did when faced with the advent of photoshopped imagery.   (Resnick, 2018) To achieve this, Resnick provides a blunt suggestion for online audiences: </p>
    <br>
    <p class= "justify">“Just because you’ve seen it with your own eyes in a video isn’t enough to conclude that it really happened.”</p>


</div>
    <div id="page4" class="smooth"></a>
        <div class="page-content">

          <h1>Conclusion</h1>
          <br>
          <h2>So, where does this leave us?</h2>
          <br>
          <br>
          <p class= "justify">To conclude, whilst the world won’t come to an end just because some people couldn’t guess the fake in this assignment survey, or on the aforementioned ABC article, the tendencies illuminated by these leave the door ajar for possibilities of more sinister ‘deep fakes’ in the future.</p>
          <br>
          <br>
          <p class= "justify">And so, whilst this modern age of deceptive and distorted media may leave us with only a murky sense of truth, it is paramount that one thing remains clear throughout; </p>
          <br>
          <br>
          <p class="justify">Algorithms won’t save us, and nor will experts.</p>
          <br>
          <br>
          <p class="justify">But being more critically thinking humans might.</p>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <h2>Bibliograhy</h2>
          <br>
          <br>
          <p class="justify"> Blitz, M. J. (2018). Lies, Line Drawing, and (Deep) Fake News. Oklahoma Law Review, 59-63.</p>
          <br>
          <p class="justify">Chesney, R., & Citron, D. (2018, February 21). Deep Fakes: A Looming Crisis for National Security, Democracy and Privacy? Retrieved from Lawfare: https://www.lawfareblog.com/deep-fakes-looming-crisis-national-security-democracy-and-privacy</p>
          <br>
          <p class="justify">Cole, S. (2017, December 12). AI-Assisted Fake Porn Is Here and We’re All Fucked. Retrieved from Motherboard: https://motherboard.vice.com/en_us/article/gydydm/gal-gadot-fake-ai-porn</p>
          <br>
          <p class="justify">Cole, S. (2018, August 15). There Is No Tech Solution to Deepfakes. Retrieved from Motherboard: https://motherboard.vice.com/en_us/article/594qx5/there-is-no-tech-solution-to-deepfakes</p>
          <br>
          <p class="justify">Combes, B. A. (2008). The Net Generation: Tech-savvy or lost in virtual space? Perth: ResearchGate.</p>
          <br>
          <p class="justify">Descartes, R. (1641). Meditations on First Philosophy . Cottingham.</p>
          <br>
          <p class="justify">Dick, P. K. (1957). The Cosmic Puppets. Boston: First Mariner Books.</p>
          <br>
          <p class="justify">Lesie, T., Hoad, N., & Spraggon, B. (2018, September 27). Can you tell a fake video from a real one? Retrieved from ABC: https://www.abc.net.au/news/2018-09-27/fake-news-part-one/10308638</p>
          <br>
          <p class="justify">Resnick, P. (2018, October 15). Why deepfakes are a real threat to elections and society. (T. Maddox, Interviewer)</p>
          <br>
          <p class="justify">Wang, Y. (2007). Riding to the future - an investigation of information literacy skills of students at an urban university as applied to the web environment. International Journal on ELearning, 593.</p>
          <br>
          <p class="justify">Westphal, G. (2005). THE GREENWOOD ENCYCLOPEDIA OF SCIENCE FICTION. New York: Greenwood Press.</p>
          <br>
          <br>
    </div>

</body>

<footer>
  <p>Copyright 2018, James Finnimore</p>
</footer>
